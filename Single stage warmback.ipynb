{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3266617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import random\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    #device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "m=900#m+1 spacial nodes in total\n",
    "Nnn=880+450+600\n",
    "heat_up_number=10#number of warmback stages\n",
    "\n",
    "os.chdir('/kaggle/input/multistagesinglefracture440')\n",
    "XX_0= np.array(pd.read_csv('T_heatup_multistage_440.csv'))#take warmback stage temperature in wellbore\n",
    "y_mm_0=np.array(pd.read_csv('position_multistage_singlefracture440.csv'))#take fracture labels along wellbore\n",
    "real_position_0=np.array(pd.read_csv('singlefracture_multistage_realposition_440.csv'))#take real wellbore depth\n",
    "XX_0=XX_0.reshape(440,m+1,heat_up_number)\n",
    "XX_0=XX_0.transpose(0,2,1)\n",
    "real_position_0=real_position_0.reshape(440,m+1,heat_up_number)\n",
    "real_position_0=real_position_0.transpose(0,2,1)#(number_samples,heatup_stage,m=901)\n",
    "\n",
    "os.chdir('/kaggle/input/multistagesinglefracturelater440')\n",
    "XX_1= np.array(pd.read_csv('T_heatup_multistage_11.csv'))#(440*(m+1),heat_up_number)\n",
    "y_mm_1=np.array(pd.read_csv('position_multistage_singlefracture111.csv'))#(440*heat_up_number,m+1)\n",
    "real_position_1=np.array(pd.read_csv('singlefracture_multistage_realposition_11.csv'))#(440*(m+1),heat_up_number)\n",
    "XX_1=XX_1.reshape(440,m+1,heat_up_number)\n",
    "XX_1=XX_1.transpose(0,2,1)\n",
    "real_position_1=real_position_1.reshape(440,m+1,heat_up_number)\n",
    "real_position_1=real_position_1.transpose(0,2,1)\n",
    "os.chdir('/kaggle/input/injection900')\n",
    "T_inj_0=np.array(pd.read_csv('T_injection_train.csv')).reshape(880,m+1,22)[:440,:,0]\n",
    "T_inj_1=np.array(pd.read_csv('T_injection_train.csv')).reshape(880,m+1,22)[440:,:,0]\n",
    "Position_check=np.array(pd.read_csv('position_heatup_train.csv'))\n",
    "\n",
    "os.chdir('/kaggle/input/3to5fractures')\n",
    "y_mm_2=np.array(pd.read_csv('position_heatup_train_3to5_fracture.csv'))\n",
    "T_inj_2=np.array(pd.read_csv('T_injection_train_3to5_fracture.csv')).reshape(450,m+1,22)[:,:,0]\n",
    "os.chdir('/kaggle/input/multistage3ro5fracture450')\n",
    "XX_2= np.array(pd.read_csv('3to5fracture_T_heatup_multistage450.csv'))\n",
    "real_position_2=np.array(pd.read_csv('3to5fracture_multistage_realposition450.csv'))\n",
    "XX_2=XX_2.reshape(450,m+1,heat_up_number)\n",
    "XX_2=XX_2.transpose(0,2,1)\n",
    "real_position_2=real_position_2.reshape(450,m+1,heat_up_number)\n",
    "real_position_2=real_position_2.transpose(0,2,1)\n",
    "os.chdir('/kaggle/input/2frac-multistage-variousflowrate-600-600')\n",
    "index_frac1=np.array(pd.read_csv('fracture_L1_2frac_variousflowrate_0512.csv'))\n",
    "y_mm_3=np.array(pd.read_csv('position_heatup_train_2frac_variousflowrate_0512.csv'))\n",
    "T_inj_3=np.array(pd.read_csv('T_injection_train_2frac_variousflowrate_0512.csv')).reshape(600,m+1,22)[:,:,0]\n",
    "frac_mm_singlestage1=np.array(pd.read_csv('fracflowrate_heatup_train_2frac_variousflowrate_0512.csv'))\n",
    "XX_3= np.array(pd.read_csv('2fracture_variousflowrate_T_heatup_multistage_0512.csv'))\n",
    "real_position_3=np.array(pd.read_csv('2fracture_variousflowrate_multistage_realposition_0512 .csv'))\n",
    "Nnn2=600\n",
    "heat_up_number=10\n",
    "XX_3=XX_3.reshape(Nnn2,m+1,heat_up_number)\n",
    "XX_3=XX_3.transpose(0,2,1)\n",
    "real_position_3=real_position_3.reshape(Nnn2,m+1,heat_up_number)\n",
    "real_position_3=real_position_3.transpose(0,2,1)\n",
    "XX=np.zeros((Nnn,heat_up_number,m+1))\n",
    "TT_inj=np.zeros((Nnn,m+1))\n",
    "XX=torch.cat((torch.Tensor(XX_0),torch.Tensor(XX_1),torch.Tensor(XX_2),torch.Tensor(XX_3)),dim=0)\n",
    "XX=XX.numpy()\n",
    "XX=XX.reshape(Nnn*heat_up_number,m+1)\n",
    "TT_inj=torch.cat((torch.Tensor(T_inj_0),torch.Tensor(T_inj_1),torch.Tensor(T_inj_2),torch.Tensor(T_inj_3)),dim=0)\n",
    "TT_inj=TT_inj.numpy()\n",
    "real_position=np.zeros((Nnn,heat_up_number,m+1))\n",
    "real_position=torch.cat((torch.Tensor(real_position_0),torch.Tensor(real_position_1),torch.Tensor(real_position_2),torch.Tensor(real_position_3)),dim=0)                          \n",
    "real_position=real_position.numpy()\n",
    "real_position=real_position.reshape(Nnn*heat_up_number,m+1)\n",
    "y_mm=np.zeros((Nnn,m+1))\n",
    "y_mm_00=y_mm_0.reshape(440,heat_up_number,m+1)[:,0,:]\n",
    "y_mm_11=y_mm_1.reshape(440,heat_up_number,m+1)[:,0,:]\n",
    "y_mm=torch.cat((torch.Tensor(y_mm_00),torch.Tensor(y_mm_11),torch.Tensor(y_mm_2),torch.Tensor(y_mm_3)),dim=0)                        \n",
    "y_mm=y_mm.numpy()\n",
    "#interpolate\n",
    "XX_new=np.zeros((Nnn*heat_up_number,m+1))\n",
    "real_position_new=np.zeros((Nnn*heat_up_number,m+1))\n",
    "TT_inj_new=np.zeros((Nnn,m+1))\n",
    "for i in range(0,Nnn*heat_up_number):\n",
    "    real_position_new[i,0:895]=np.arange(0,895)\n",
    "    real_position_new[i,895]=894.5\n",
    "    real_position_new[i,896]=895\n",
    "    real_position_new[i,897]=895.5\n",
    "    real_position_new[i,898]=896\n",
    "    real_position_new[i,899]=896.5\n",
    "    real_position_new[i,900]=897\n",
    "    real_position_new[i,0]=1.05\n",
    "for i in range(0,Nnn*heat_up_number):\n",
    "    f = interpolate.interp1d(real_position[i,:], XX[i,:])\n",
    "    XX_new[i,:]=f(real_position_new[i,:]) \n",
    "\n",
    "XX_new=XX_new.reshape(Nnn,heat_up_number,m+1)\n",
    "#normalize temp, every sample for all heatup stages uses the same max and min\n",
    "for i in range(Nnn):\n",
    "    XX_new[i,:,:]=(XX_new[i,:,:]-np.min(XX_new[i,:,:]))/(np.max(XX_new[i,:,:])-np.min(XX_new[i,:,:]))\n",
    "real_position_new=real_position_new.reshape(Nnn,heat_up_number,m+1)\n",
    "#injection data interpolation\n",
    "real_position=real_position.reshape(Nnn,heat_up_number,m+1)\n",
    "for j in range(0,Nnn):\n",
    "    ff = interpolate.interp1d(real_position[j,0,:], TT_inj[j,:])\n",
    "    TT_inj_new[j,:]=ff(real_position_new[j,0,:]) \n",
    "for i in range(Nnn):\n",
    "    TT_inj_new[i,:]=(TT_inj_new[i,:]-np.min(TT_inj_new[i,:]))/(np.max(TT_inj_new[i,:])-np.min(TT_inj_new[i,:]))    \n",
    "    \n",
    "XXXX=np.zeros((Nnn,heat_up_number+1,len(XX_new[0,0,:])))\n",
    "XXXX[:,0,:]=TT_inj_new\n",
    "XXXX[:,1:,:]=XX_new\n",
    "N_validate=530\n",
    "Index=random.sample(range(0,Nnn),Nnn-N_validate)\n",
    "X_train=np.zeros((Nnn-N_validate,heat_up_number+1,len(XX_new[0,0,:])))\n",
    "y_train=np.zeros((Nnn-N_validate,len(XX_new[0,0,:])))\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "for j in range(0,Nnn-N_validate):\n",
    "    X_train[j]=XXXX[Index[j],:,:]\n",
    "    y_train[j]=y_mm[Index[j],:]\n",
    "aa=list(np.arange(0,Nnn))\n",
    "cc=[x for x in aa if x in Index]\n",
    "dd=[y for y in (aa+list(Index))if y not in cc]\n",
    "for h in range(len(dd)):\n",
    "    XXXX[dd[h],:,:]=XXXX[dd[h],:,:]\n",
    "    X_test.append(XXXX[dd[h],:,:])\n",
    "    y_test.append(y_mm[dd[h],:])\n",
    "y_train_tensors = torch.LongTensor(y_train)\n",
    "y_test_tensors = torch.LongTensor(np.array(y_test))\n",
    "#add noise to input\n",
    "noise_std_input = 0\n",
    "X_train_noisy = X_train + noise_std_input * np.random.randn(*np.array(X_train).shape)\n",
    "X_test_noisy=X_test + noise_std_input * np.random.randn(*np.array(X_test).shape)\n",
    "X_train_tensors=torch.Tensor(X_train_noisy[:,:1,:])\n",
    "X_test_tensors=torch.Tensor(X_test_noisy[:,:1,:])\n",
    "\n",
    "\n",
    "class TemDataset(Dataset):\n",
    "    def __init__(self,X_train_tensors,y_train_tensors):\n",
    "        self.x=X_train_tensors\n",
    "        self.y=y_train_tensors\n",
    "        self.n_samples=self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset=TemDataset(X_train_tensors,y_train_tensors)\n",
    "dataloader=DataLoader(dataset=dataset,batch_size=256,shuffle=True)#444\n",
    "print(\"Training Shape\", X_train_tensors.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape\", X_test_tensors.shape, y_test_tensors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca461ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single stage warmback\n",
    "Num_feature=1\n",
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length,embed_size=40*2,heads=1,drop_prob=0):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "        self.embed_size=embed_size\n",
    "        self.heads=heads\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True,bidirectional=True,dropout=drop_prob) #lstm\n",
    "        self.gru=nn.GRU(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True,dropout=drop_prob)\n",
    "        self.multiattention=nn.MultiheadAttention(embed_size,heads,dropout=drop_prob)\n",
    "        self.ln=nn.LayerNorm(normalized_shape=seq_length,eps=1.0e-5)\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)).to(device) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)).to(device) #internal state\n",
    "        x=self.ln(x.transpose(2,1))#add layer_norm\n",
    "        x=x.transpose(2,1)\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        out = output\n",
    "        return out    \n",
    "class FCN(nn.Module):\n",
    "    def __init__(self,c_in=Num_feature, c_out=1, layers=[128, 256, 128], kss=[7, 5, 3],embed_size1=128,embed_size2=256,heads=1,drop_prob=0):#c_in是feacture number\n",
    "        super(FCN, self).__init__()\n",
    "        assert len(layers) == len(kss)\n",
    "        self.convblock1 = nn.Conv1d(c_in, layers[0], kss[0])\n",
    "        self.convblock2 = nn.Conv1d(layers[0], layers[1], kss[1])\n",
    "        self.convblock3 = nn.Conv1d(layers[1], layers[2], kss[2])\n",
    "        self.gap=torch.nn.AdaptiveAvgPool1d((m+1))\n",
    "        self.fc = nn.Linear((layers[2]+2*40), 10)\n",
    "        self.fcc = nn.Linear(10,2)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "        self.prelu=nn.PReLU()\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.bn1=nn.BatchNorm1d(layers[0],eps=1e-03,momentum=0.99)\n",
    "        self.bn2=nn.BatchNorm1d(layers[1],eps=1e-03,momentum=0.99)\n",
    "        self.bn3=nn.BatchNorm1d(layers[2],eps=1e-03,momentum=0.99)\n",
    "        self.dropout=nn.Dropout(p=0)\n",
    "        self.lstm1 = LSTM1(num_classes=m+1, input_size=Num_feature, hidden_size=40, num_layers=2,seq_length=m+1).to(device)#input_size=feacture number\n",
    "    def forward(self, x):\n",
    "        x_fcn = self.convblock1(x)\n",
    "        x_fcn=self.bn1(x_fcn)\n",
    "        x_fcn=self.relu(x_fcn)\n",
    "        x_fcn = self.convblock2(x_fcn)\n",
    "        x_fcn=self.bn2(x_fcn)\n",
    "        x_fcn=self.relu(x_fcn)\n",
    "        x_fcn = self.convblock3(x_fcn)\n",
    "        x_fcn=self.bn3(x_fcn)\n",
    "        x_fcn=self.relu(x_fcn)\n",
    "        x_fcn = self.gap(x_fcn)#size(N,C,m+1)\n",
    "        x_fcn=x_fcn.transpose(1,2)\n",
    "        ####LSTM\n",
    "        x_lstm=x.transpose(1,2)\n",
    "        x_lstm=self.lstm1(x_lstm)\n",
    "        ###concat\n",
    "        out_concat = torch.cat((x_lstm,x_fcn),2)\n",
    "        out_concat=self.prelu(out_concat)\n",
    "        out_concat=self.fc(out_concat)\n",
    "        out_concat=self.prelu(out_concat)\n",
    "        out_concat=self.fcc(out_concat)#size(N,m+1,2)\n",
    "        outt=out_concat.transpose(1,2)#size(N,2,m+1)\n",
    "        out_concat=self.prelu(outt)\n",
    "        out_concat=self.softmax(outt)#calculate along dim=1\n",
    "        return out_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 800 #changale num of epochs\n",
    "learning_rate = 0.005#changable learning rate\n",
    "fcn = FCN().to(device) \n",
    "weight=torch.Tensor([1,100]).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weight)#weighted crossentropy loss\n",
    "optimizer = torch.optim.Adam(fcn.parameters(), lr=learning_rate) \n",
    "scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=50,\n",
    " verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(inputs,labels) in enumerate(dataloader):  \n",
    "        outputs = fcn.forward(inputs.to(device)) #forward pass\n",
    "        loss = criterion(outputs, labels.to(device)) #forCrossEntropyLoss0411\n",
    "        loss.backward() #calculates the loss of the loss function\n",
    "        optimizer.step() #improve from loss, i.e backprop\n",
    "        optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "    if epoch % 100 == 0:\n",
    "              losses.append(loss.item())\n",
    "              print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b012cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy matrix:\n",
    "train_predict1 = fcn(X_test_tensors.to(device))#forward pass\n",
    "train_predict1=train_predict1.cpu()\n",
    "data_predict = train_predict1.data.numpy() #numpy conversion\n",
    "dataY_plot = y_test_tensors.data.numpy()\n",
    "data_predict1=data_predict[:,1,:]\n",
    "label_predicted=np.argwhere(np.around(data_predict1)==1)\n",
    "label_real1=np.argwhere(dataY_plot==1)\n",
    "sum_real=0\n",
    "sum_predicted=0\n",
    "for i in range (label_real1.shape[0]):\n",
    "    for any in data_predict1[label_real1[i][0],label_real1[i][1]-4:label_real1[i][1]+5]:\n",
    "        if any>=0.5:\n",
    "            sum_real=sum_real+1\n",
    "            break\n",
    "for j in range(label_predicted.shape[0]):\n",
    "    for any in dataY_plot[label_predicted[j][0],label_predicted[j][1]-4:label_predicted[j][1]+5]:\n",
    "        if any==1:\n",
    "            sum_predicted=sum_predicted+1\n",
    "            break     \n",
    "accuracy=2/(1/(sum_real/label_real1.shape[0])+1/(sum_predicted/label_predicted.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f05f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test a real case\n",
    "#figure 6\n",
    "m=900\n",
    "os.chdir(\"/kaggle/input/modelfcn\")\n",
    "model=torch.load('single_warmback_prediction_0314_accuracy_99_76_utego_spike.pt')\n",
    "os.chdir('/kaggle/input/ugeto-spike0121')\n",
    "realposition=np.array(pd.read_csv('ugeto_spike.csv'))[0:1,:]#(10*582)\n",
    "temp=np.array(pd.read_csv('ugeto_spike.csv'))[1:2,:]#(10*582)\n",
    "XX_new11=np.zeros((1,m+1))\n",
    "real_position_new11=np.zeros((1,m+1))\n",
    "for i in range(0,1):\n",
    "    real_position_new11[i,0:901]=np.arange(2450.582,2800,(2800-2451)/900)[0:901]\n",
    "for i in range(0,1):\n",
    "    f = interpolate.interp1d(realposition[i,:], temp[i,:])\n",
    "    XX_new11[i,:]=f(real_position_new11[i,:])\n",
    "XX_new11=(XX_new11-np.min(XX_new11))/(np.max(XX_new11)-np.min(XX_new11))\n",
    "X_test_tensors2=torch.Tensor(np.zeros((1,901)))\n",
    "X_test_tensors2[0,:]= Variable(torch.Tensor(XX_new11[0,:]))\n",
    "X_test_tensors1=X_test_tensors2.unsqueeze(0)\n",
    "train_predict2 = model(X_test_tensors1.to(device))#forward pass\n",
    "train_predict2=train_predict2.cpu()\n",
    "data_predict2 = train_predict2.data.numpy() #numpy conversion\n",
    "#figure 6 in paper\n",
    "os.chdir('/kaggle/input/ugeto-spike-frac-labels')\n",
    "y_label=np.array(pd.read_csv('ugeto_spike_frac_labels.csv'))#(number_samples,m=901)\n",
    "y_label[0,0]=2491.28\n",
    "import matplotlib.patches as patches\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "for i in range(0,9,2):\n",
    "    rect = plt.Rectangle((y_label[0,i],0),y_label[0,i+1]-y_label[0,i],1, fill=True, color = \"#C5C9C7\",linewidth=1)\n",
    "    ax.add_patch(rect)\n",
    "rect = plt.Rectangle((y_label[0,10],0),y_label[0,11]-y_label[0,10],1, fill=True, color = \"#C5C9C7\",label=\"Labeled fracture zones\")\n",
    "ax.add_patch(rect)\n",
    "ax.plot(real_position_new11[0,:],np.round(data_predict2[0,1,:]),\"r-\",linewidth=0.7,label=\"Predicted fractures\")\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(real_position_new11[0,:],XX_new11[0,:],\"b-\",linewidth=1,label=\"Warmback temperature\")\n",
    "fig.legend(loc=6, bbox_to_anchor=(0.95,0.1))#, bbox_transform=ax.transAxes)\n",
    "ax.set_ylabel(\"Fracture probability/[-]\",color=\"r\")\n",
    "ax2.set_ylabel(\"Dimensionless wellbore temperature/[-]\",color=\"b\")\n",
    "ax.set_xlabel(\"Depth/m\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
